{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe-C-Sturm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeines\n",
    "\n",
    "Eine allgemeine Beschreibung der Laboraufgaben inklusive des Vorgehens, den Bewertungsrichtlinien und der Abgabe finden Sie  <a href=\"ML-allgemein.ipynb\">hier</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenquelle\n",
    "\n",
    "\n",
    "* Laden Sie ihre Daten von http://141.72.190.207/ml_lab/C_sturm herunter\n",
    "    * Die Daten sind geschützt. \n",
    "        * Sie müssen evtl. in einem Netzwerk der DHBW (z.B. WLAN, VPN, ...) angemeldet sein. \n",
    "        * Sie können sich auf der Webseite mit dem Benutzernamen dhbw und dem Zugangsnamen \"ml_LaB_4$\" anmelden. \n",
    "* Die Daten sind in einem anwendungsspezifischen Format gespeichert.\n",
    "    * Sie finden evtl. Informationen über die Daten in einer \"README\" Datei. \n",
    "    * Finden Sie keine solche Datei sind die Daten selbst erklärend. \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sagen Sie die Windgeschwindigkeit eines Sturms (in Knoten) aufgrund von Satellitenfotos vorher.\n",
    "Der Datensatz besteht aus Fotos von 494 verschiedenen Stürmen im Atlantik und Pazifik mit ihren zugehörigen Windgeschwindigkeiten.\n",
    "Jedes Bild hat `366 x 366` Pixel, und es sind 70.257 Trainingsdaten und 45.377 Testdaten vorhanden.\n",
    "Die Bilder wurden zu mehreren Zeitpunkten während der Lebensdauer eines Sturms aufgenommen.\n",
    "\n",
    "Für jeden Sturm im Trainings und Testdatensatz erhalten Sie eine Zeitreihe von Bildern mit der jeweiligen assoziierten relativen Zeit seit Beginn des Sturms.\n",
    "Ihr Modell sollte neben den reinen Bilddaten also auch den zeitlichen Verlauf des Sturms betrachten, um die Vorhersage für künftige Vorhersagezeitpunkte zu erstellen\n",
    "\n",
    "Die Bilder sind nach folgendem Schema benannt: `{image_id}.jpg`.\n",
    "Diese IDs bestehen aus einer Sturm_ID und einer Bildnummer entsprechend der zeitlichen Bildreihenfolge.\n",
    "\n",
    "Ihr Ziel ist es, für die Testdaten die korrekte Windgeschwindigkeiten vorherzusagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösung\n",
    "\n",
    "* Beginnen Sie hier mit Ihrer Dokumentation und Implementierung! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geplantes Vorgehen: \n",
    "\n",
    "- Daten vorbereitung\n",
    "- CNN-Modell trainieren (für räumliche Merkmale der Bilder)\n",
    "- LSTM-Modell trainieren (für zeitlichen Verlauf der Bilder)\n",
    "- Kombinierung der Modelle (Fully Connected-Layer um CNN in LSTM einzuspeisen, Ausgabe von LSTM ist finale Vorhersage)\n",
    "- Kombinierte Modell auf Trainingsdaten trainieren "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'storm_train_data\\\\acd_123\\\\features.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21968\\3540133810.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# Load the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21968\\3540133810.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstorm_dir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorm_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mimg_sequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_storm_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorm_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[0mtest_img_sequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mtest_label_sequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21968\\3540133810.py\u001b[0m in \u001b[0;36mload_storm_data\u001b[1;34m(storm_dir)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_storm_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorm_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Load the features for this storm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorm_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'features.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Load the labels for this storm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'storm_train_data\\\\acd_123\\\\features.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Set the paths to the data directories\n",
    "train_data_dir = 'storm_train_data'\n",
    "train_labels_dir = 'storm_train_labels'\n",
    "test_data_dir = 'storm_test_data'\n",
    "test_labels_dir = 'storm_test_labels'\n",
    "\n",
    "# Define the image size and number of channels\n",
    "img_size = (366, 366)\n",
    "num_channels = 1\n",
    "\n",
    "# Define the sequence length\n",
    "seq_length = 10\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def load_image(file_path):\n",
    "    img = Image.open(file_path).convert('L') # Open the image and convert to grayscale\n",
    "    img = img.resize(img_size) # Resize the image\n",
    "    img_array = np.array(img) # Convert to numpy array\n",
    "    img_array = img_array.reshape((*img_size, num_channels)) # Add channel dimension\n",
    "    img_array = img_array / 255.0 # Normalize pixel values to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Function to load and preprocess the data for a single storm\n",
    "def load_storm_data(storm_dir):\n",
    "    # Load the features for this storm\n",
    "    with open(os.path.join(train_data_dir, storm_dir, 'features.json'), 'r') as f:\n",
    "        features = json.load(f)\n",
    "    # Load the labels for this storm\n",
    "    with open(os.path.join(train_labels_dir, storm_dir, 'labels.json'), 'r') as f:\n",
    "        labels = json.load(f)\n",
    "    # Load and preprocess the images for this storm\n",
    "    img_sequences = []\n",
    "    label_sequences = []\n",
    "    for i, img_id in enumerate(features.keys()):\n",
    "        # Load the image\n",
    "        img = load_image(os.path.join(train_data_dir, storm_dir, 'image.jpg'))\n",
    "        # Add the image to the sequence\n",
    "        if i >= seq_length - 1:\n",
    "            img_seq = [load_image(os.path.join(train_data_dir, storm_dir, f'image_{j}.jpg')) \n",
    "                       for j in range(i-seq_length+1, i+1)]\n",
    "            img_sequences.append(np.concatenate(img_seq, axis=-1))\n",
    "            label_sequences.append(labels[img_id]['wind_speed'])\n",
    "    return np.array(img_sequences), np.array(label_sequences)\n",
    "\n",
    "# Function to load and preprocess the data for all storms\n",
    "def load_data():\n",
    "    # Load and preprocess the training data\n",
    "    train_img_sequences = []\n",
    "    train_label_sequences = []\n",
    "    for storm_dir in os.listdir(train_data_dir):\n",
    "        if os.path.isdir(os.path.join(train_data_dir, storm_dir)):\n",
    "            img_sequences, label_sequences = load_storm_data(storm_dir)\n",
    "            train_img_sequences.append(img_sequences)\n",
    "            train_label_sequences.append(label_sequences)\n",
    "    train_img_sequences = np.concatenate(train_img_sequences, axis=0)\n",
    "    train_label_sequences = np.concatenate(train_label_sequences, axis=0)\n",
    "    # Load and preprocess the test data\n",
    "    test_img_sequences = []\n",
    "    test_label_sequences = []\n",
    "    for storm_dir in os.listdir(test_data_dir):\n",
    "        if os.path.isdir(os.path.join(test_data_dir, storm_dir)):\n",
    "            img_sequences, label_sequences = load_storm_data(storm_dir)\n",
    "            test_img_sequences.append(img_sequences)\n",
    "            test_label_sequences.append(label_sequences)\n",
    "    test_img_sequences = np.concatenate(test_img_sequences, axis=0)\n",
    "    test_label_sequences = np.concatenate(test_label_sequences, axis=0)\n",
    "    return train_img_sequences, train_label_sequences, test_img_sequences, test_label_sequences\n",
    "\n",
    "# Load the data\n",
    "train_data, train_labels, test_data, test_labels = load_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
