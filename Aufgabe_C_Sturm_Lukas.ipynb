{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe-C-Sturm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeines\n",
    "\n",
    "Eine allgemeine Beschreibung der Laboraufgaben inklusive des Vorgehens, den Bewertungsrichtlinien und der Abgabe finden Sie  <a href=\"ML-allgemein.ipynb\">hier</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenquelle\n",
    "\n",
    "\n",
    "* Laden Sie ihre Daten von http://141.72.190.207/ml_lab/C_sturm herunter\n",
    "    * Die Daten sind geschützt. \n",
    "        * Sie müssen evtl. in einem Netzwerk der DHBW (z.B. WLAN, VPN, ...) angemeldet sein. \n",
    "        * Sie können sich auf der Webseite mit dem Benutzernamen dhbw und dem Zugangsnamen \"ml_LaB_4$\" anmelden. \n",
    "* Die Daten sind in einem anwendungsspezifischen Format gespeichert.\n",
    "    * Sie finden evtl. Informationen über die Daten in einer \"README\" Datei. \n",
    "    * Finden Sie keine solche Datei sind die Daten selbst erklärend. \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sagen Sie die Windgeschwindigkeit eines Sturms (in Knoten) aufgrund von Satellitenfotos vorher.\n",
    "Der Datensatz besteht aus Fotos von 494 verschiedenen Stürmen im Atlantik und Pazifik mit ihren zugehörigen Windgeschwindigkeiten.\n",
    "Jedes Bild hat `366 x 366` Pixel, und es sind 70.257 Trainingsdaten und 45.377 Testdaten vorhanden.\n",
    "Die Bilder wurden zu mehreren Zeitpunkten während der Lebensdauer eines Sturms aufgenommen.\n",
    "\n",
    "Für jeden Sturm im Trainings und Testdatensatz erhalten Sie eine Zeitreihe von Bildern mit der jeweiligen assoziierten relativen Zeit seit Beginn des Sturms.\n",
    "Ihr Modell sollte neben den reinen Bilddaten also auch den zeitlichen Verlauf des Sturms betrachten, um die Vorhersage für künftige Vorhersagezeitpunkte zu erstellen\n",
    "\n",
    "Die Bilder sind nach folgendem Schema benannt: `{image_id}.jpg`.\n",
    "Diese IDs bestehen aus einer Sturm_ID und einer Bildnummer entsprechend der zeitlichen Bildreihenfolge.\n",
    "\n",
    "Ihr Ziel ist es, für die Testdaten die korrekte Windgeschwindigkeiten vorherzusagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösung\n",
    "\n",
    "* Beginnen Sie hier mit Ihrer Dokumentation und Implementierung! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geplantes Vorgehen: \n",
    "\n",
    "- Daten vorbereitung\n",
    "- CNN-Modell trainieren (für räumliche Merkmale der Bilder)\n",
    "- LSTM-Modell trainieren (für zeitlichen Verlauf der Bilder)\n",
    "- Kombinierung der Modelle (Fully Connected-Layer um CNN in LSTM einzuspeisen, Ausgabe von LSTM ist finale Vorhersage)\n",
    "- Kombinierte Modell auf Trainingsdaten trainieren "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das geplante Vorgehen für die Vorhersage von Windgeschwindigkeiten eines Sturms aufgrund von Satellitenfotos mithilfe von tiefen neuronalen Netzen kann wie folgt aussehen:\n",
    "\n",
    "1. Datenanalyse: Zunächst sollten die Trainings- und Testdaten untersucht werden, um eine Vorstellung davon zu bekommen, wie die Daten strukturiert sind und wie die Windgeschwindigkeiten mit den Bilddaten und dem zeitlichen Verlauf des Sturms korrelieren.\n",
    "\n",
    "2. Datenpräparation: Die Bilddaten können normalisiert und in eine geeignete Form gebracht werden, um sie für das Training des neuronalen Netzes zu verwenden. Dabei kann auch die Information über den zeitlichen Verlauf des Sturms in die Datensätze integriert werden.\n",
    "\n",
    "3. Modellierung: Es kann ein tiefes neuronales Netzwerk entworfen werden, das die Bilddaten und die Information über den zeitlichen Verlauf des Sturms als Eingabe erhält und die Windgeschwindigkeit als Ausgabe generiert. Hierbei können verschiedene Architekturen von neuronalen Netzen ausprobiert werden, um das beste Ergebnis zu erzielen.\n",
    "\n",
    "4. Training: Das entworfene Modell kann mit den Trainingsdaten trainiert werden. Dabei sollten geeignete Verlustfunktionen und Optimierer gewählt werden, um die Leistung des Modells zu verbessern.\n",
    "\n",
    "5. Evaluierung: Nach dem Training sollte die Leistung des Modells mit den Testdaten ausgewertet werden, um zu überprüfen, ob es in der Lage ist, die Windgeschwindigkeiten korrekt vorherzusagen.\n",
    "\n",
    "6. Feintuning: Wenn das Modell nicht zufriedenstellend abschneidet, kann es durch Feintuning verbessert werden, indem z.B. die Hyperparameter optimiert werden.\n",
    "\n",
    "7. Anwendung: Wenn das Modell gut funktioniert, kann es für Vorhersagen von Windgeschwindigkeiten von Stürmen aufgrund von Satellitenfotos verwendet werden.\n",
    "\n",
    "Es ist zu beachten, dass es bei jedem Schritt des oben beschriebenen Vorgehens viele Möglichkeiten und Entscheidungen gibt, die je nach den Eigenschaften der Daten und des Modells angepasst werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing label data for image image.jpg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lukas\\source\\repos\\MLLab\\ML_Lab_Sturm_TINF20IT1\\Aufgabe_C_Sturm_Lukas.ipynb Cell 11\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/source/repos/MLLab/ML_Lab_Sturm_TINF20IT1/Aufgabe_C_Sturm_Lukas.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data, labels\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/source/repos/MLLab/ML_Lab_Sturm_TINF20IT1/Aufgabe_C_Sturm_Lukas.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Laden der Trainingsdaten\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lukas/source/repos/MLLab/ML_Lab_Sturm_TINF20IT1/Aufgabe_C_Sturm_Lukas.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m train_data, train_labels \u001b[39m=\u001b[39m load_data(\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/source/repos/MLLab/ML_Lab_Sturm_TINF20IT1/Aufgabe_C_Sturm_Lukas.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(train_data)\u001b[39m}\u001b[39;00m\u001b[39m Trainingsbilder und \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(train_labels)\u001b[39m}\u001b[39;00m\u001b[39m Trainingslabels gefunden.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/source/repos/MLLab/ML_Lab_Sturm_TINF20IT1/Aufgabe_C_Sturm_Lukas.ipynb#X12sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Laden der Testdaten\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\source\\repos\\MLLab\\ML_Lab_Sturm_TINF20IT1\\Aufgabe_C_Sturm_Lukas.ipynb Cell 11\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/source/repos/MLLab/ML_Lab_Sturm_TINF20IT1/Aufgabe_C_Sturm_Lukas.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m image_id \u001b[39m=\u001b[39m folder_name\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/source/repos/MLLab/ML_Lab_Sturm_TINF20IT1/Aufgabe_C_Sturm_Lukas.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m image_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m label_data:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lukas/source/repos/MLLab/ML_Lab_Sturm_TINF20IT1/Aufgabe_C_Sturm_Lukas.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMissing label data for image \u001b[39m\u001b[39m{\u001b[39;00mfile_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/source/repos/MLLab/ML_Lab_Sturm_TINF20IT1/Aufgabe_C_Sturm_Lukas.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m label \u001b[39m=\u001b[39m label_data[image_id]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lukas/source/repos/MLLab/ML_Lab_Sturm_TINF20IT1/Aufgabe_C_Sturm_Lukas.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(label, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m)):\n",
      "\u001b[1;31mValueError\u001b[0m: Missing label data for image image.jpg"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = 'data' # Verzeichnis in dem die Daten gespeichert sind\n",
    "\n",
    "def load_data(data_type):\n",
    "    data_path = os.path.join(data_dir, f'storm_{data_type}_data')\n",
    "    label_path = os.path.join(data_dir,f'storm_{data_type}_labels')\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for folder_name in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, folder_name)\n",
    "        label_file = os.path.join(label_path,folder_name, 'labels' + '.json')\n",
    "        with open(label_file) as f:\n",
    "            label_data = json.load(f)\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if not file_name.endswith('.jpg'):\n",
    "                continue\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            image = Image.open(image_path)\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            data.append(image)\n",
    "\n",
    "            # image_id = int(file_name[:-4])\n",
    "            image_id = folder_name\n",
    "            if image_id not in label_data:\n",
    "                raise ValueError(f'Missing label data for image {file_name}')\n",
    "            label = label_data[image_id]\n",
    "            if not isinstance(label, (float, int)):\n",
    "                raise ValueError(f'Invalid label for image {file_name}: {label}')\n",
    "            labels.append(label)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "# Laden der Trainingsdaten\n",
    "train_data, train_labels = load_data('train')\n",
    "print(f'{len(train_data)} Trainingsbilder und {len(train_labels)} Trainingslabels gefunden.')\n",
    "\n",
    "# Laden der Testdaten\n",
    "test_data, test_labels = load_data('test')\n",
    "print(f'{len(test_data)} Testbilder und {len(test_labels)} Testlabels gefunden.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = 'data' # Verzeichnis in dem die Daten gespeichert sind\n",
    "\n",
    "def load_data(data_type):\n",
    "    data_path = os.path.join(data_dir, f'storm_{data_type}_data')\n",
    "    label_path = os.path.join(data_dir,f'storm_{data_type}_labels')\n",
    "    data_arr = []\n",
    "    label_arr = []\n",
    "\n",
    "    for folder_name in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, folder_name)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name == \"features.json\":\n",
    "                data = [os.path.join(folder_path,file_name)]\n",
    "            if not file_name.endswith(\".jpg\"):\n",
    "                continue\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            with Image.open(image_path) as image:\n",
    "                image = image.resize((366,366))\n",
    "                image_array = np.array(image)\n",
    "                data.append(image_array)\n",
    "            id = folder_name\n",
    "            data.append(id)\n",
    "            data_arr.append(np.array(data))\n",
    "    for folder_name in os.listdir(label_path):\n",
    "        folder_path = os.path.join(label_path, folder_name)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if not file_name == \"labels.json\":\n",
    "                continue\n",
    "            label_file = os.path.join(label_path,folder_name, 'labels' + '.json')\n",
    "            with open(label_file) as l:\n",
    "                label_data = json.load(l)\n",
    "            label_arr.append(label_data)\n",
    "\n",
    "    return np.array(data_arr), np.array(label_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Temp\\ipykernel_9056\\498781141.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_arr.append(np.array(data))\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = load_data(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Temp\\ipykernel_9056\\498781141.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_arr.append(np.array(data))\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = load_data(\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------\n",
    "Die Daten sind nun in die Arrays geladen. Aufgeteilt in trainings-daten und trainings-labels, sowie test-daten und test-labels.\n",
    "Die Bilddateien werden auf eine einheitliche Größe skaliert und anschliessend werden die Pixel in einem Array normalisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
